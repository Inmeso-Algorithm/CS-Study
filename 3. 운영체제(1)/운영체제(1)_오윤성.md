## 운영체제의 역할
운체제의 역할은 크게 4가지가 있습니다.
1. CPU 스케줄링과 프로세스를 관리
2. 메모리 관리
3. 디스크 파일 관리
4. I/O 디바이스 관리 

## 운영체제의 구조
운영체제의 구조는 아래와 같습니다.

- 유저 프로그램
- GUI
- 시스템콜
- 커널
- 드라이버
- 하드웨어

여기서 운영체제는 `GUI`, `시스템콜`, `커널`, `드라이버`를 뜻합니다. 


### GUI란?
> 사용자가 전자장치와 상호 작용할 수 있도록 하는 사용자 인터페이스의 한 형태 

![](https://velog.velcdn.com/images/oyunseong/post/87515bbb-b7c3-4d1d-bf33-a9b1ec1cb6b6/image.png)

위 사진은 MAC m1 노트북의 GUI입니다.

### 드라이버
>하드웨어를 제어하기 위한 소프트웨어

### CUI 
> 그래픽이 아닌 명령어로 처리하는 인터페이스 

![](https://velog.velcdn.com/images/oyunseong/post/d6f61721-a338-437b-803a-7f05866b8edb/image.png)
위 사진은 MAC m1 노트북의 CUI(터미널)입니다.

### 시스템 콜
> 운영체제가 커널에 접근하기 위한 인터페이스이며 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 씁니다. 

유저 프로그램이 I/O 요청으로 트랩을 발동하면 올바른 I/O 요청인지 확인한 후 유저 모드가 시스템콜을 통해 커널 모드로 변환되어 실행됩니다. 예를 들어 I/O 요청인 fs.readFile()이라는 파일 시스템의 파일을 읽는 함수가 발동했다고 할 때,

![](https://velog.velcdn.com/images/oyunseong/post/a18c18f0-fdb4-45ad-9c03-b36a2f30de05/image.png)

사진 출처 :  https://rebro.kr/171

이때 유저모드에서 파일을 읽지 않고 커널모드로 들어가 파일을 읽고 다시 유저모드로 돌아가 그 뒤에 있는 유저 프로그램의 로직을 수행합니다. 이 과정을 통해 컴퓨터 자원에 대한 직접 접근을 차단할 수 있고 프로그램을 다른 프로그램으로부터 보호할 수 있습니다. 

요약 : 
1. 유저 모드로 함수 실행 
2. 커널모드로 변경하고 파일을 읽음
3. 유저모드로 돌아와 파일의 로직을 수행

`프로세스`나 `스레드`에서 `운영체제`로 어떠한 요청을 할 때 시스템콜이라는 인터페이스와 커널을 거쳐 운영체제에 전달됩니다. 
이 시스템콜은 하나의 추상화 계층입니다. 그렇기 때문에 이를 통해 네트워크 통신이나 데이터베이스와 같은 낮은 단계의 영영 처리에 대한 부분을 많이 신경 쓰지 않고 프로그램을 구현할 수 있는 장점이 있습니다.

### modebit
시스템콜이 작동될 때 `modebit`을 참고해서 유저 모드와 커널 모드를 구분합니다. 
modebit은 1 또는 0의 값을 가지는 플래그 변수입니다. 
카메라, 키보드 등 I/O 디바이스는 운영체제를 통해서만 작동해야 합니다. 카메라를 켜는 프로그램이 있다고 할 때, 만약 유저 모드를 기반으로 카메라가 켜진다면, 사용자가 의도하지 않았는데 공격자가 카메라를 갑자기 켤 수 있는 등 나쁜 짓을 하기가 쉽습니다. 
물론 커널 모드를 거쳐 운영체제를 통해 작동한다해도 완벽하게 막을 수는 없습니다. 
운영체제를 통해 작동하게 해야 막기가 쉽습니다. 이를 위한 장치가 modebit입니다. 
0 : 커널모드
1 : 유저모드 
유저모드일 경우에는 시스템콜을 못하게 막아서 한정된 일만 가능하게 합니다. 

위의 시스템 콜 요약처럼
1. 유저 프로그램이 카메라를 이용하려고할 때 ( 함수 호출 ) 
2. 시스템콜을 호출하고 modebit을 1에서 0으로 바꾼다. ( 커널모드로 변경 )
3. 커널모드로 카메라 기능 사용 ( 로직 수행 ) 
4. modebit을 0에서 1로 바꾸어 유저모드로 변경 ( 유저모드로 돌아와 로직 수행 )

### 커널
>운영체제의 핵심 부분이자 시스템콜 인터페이스를 제공하며 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할을 한다. 

### 컴퓨터의 요소
컴퓨터에는 CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있습니다.

### CPU
>Central Processing Unit는 산술논리연산장치, 제어장치, 레지스터로 구성되어있는 컴퓨터 장치를 말하며, 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행하는 일꾼들 입니다. 

커널이 프로그램을 메모리에 올려 프로세스로 만들면 일꾼인 CPU가 이를 처리합니다. 

### 제어장치
>CU, Control Unit는 프로세스 조작을 지시하는 CPU의 한 부품입니다. 입출력장치 간 통신을 제어하고 명령어들을 읽고 해석하며 데이터 처리를 위한 순서를 결정합니다. 

### 레지스터
>레지스터는 CPU 안에 있는 매우 빠른 임시기억장치를 가리킵니다. CPU와 직접 연결되어 있으므로 연산 속도가 메모리보다 수십 배에서 수백 배까지ㅂ 빠릅니다. CPU는 자체적으로 데이터를 저장할 방법이 없기 때문에 레지스터를 거쳐 데이터를 전달합니다. 

### 산술논리연산장치
>ALU, Arithmetic Logic Unit는 덧셈, 뺄셈 같은 두 숫자의 산술 연산과 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로입니다.


#### CPU의 연산 처리 
1. 제어장치가 메모리에 계산할 값을 로드합니ㅏ. 또한, 레지스터에도 로드합니다.
2. 제어장치가 레지스터에 있는 값을 계산하라고 산술논리연산장치에 명령합니다.
3. 제어장치가 계산된 값을 다시 레지스터에서 메모리로 계산한 값을 저장합니다.


### 인터럽트
>어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것을 말합니다. 

I/O 디바이스로 인한 인터럽트, 0으로 숫자를 나누는 산술 연산에서의 인터럽트, 프로세스 오류 등으로 발생합니다. 

인터럽트가 발생되면 인터럽트 핸들러 함수가 모여 있는 인터럽트 벡터로 가서 인터럽트 핸들로 함수가 실행됩니다. 인터럽트 간에는 우선순위가 있고 우선순위에 따라 실행되며 인터럽트는 하드웨어, 소프트웨어 인터럽트 두 가지로 나뉩니다.

#### 인터럽트 핸들러 함수 
>인터럽트가 발생했을 때 이를 핸들링하기 위한 함수. 커널 내부의 IRQ를 통해 호출되며 request_irq()를 통해 인터럽트 핸들러 함수를 등록할 수 있습니다.

### 하드웨어 인터럽트
>키보드, 마우스를 연결하는 과정에서 발생하는 인터럽트입니다. 

인터럽트 라인이 설계된 이후 순차적인 인터럽트 실행을 중지하고 운영체제에 시스템콜을 요청해서 원하는 디바이스로 향해 디바이스에 있는 작은 로컬 버퍼에 접근하여 일을 수행합니다.

### 소프트웨어 인터럽트 
> 트랩(trap)이라고 불립니다. 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발생합니다. 

### DMA 컨트롤러
> I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치를 뜻합니다.

CPU에만 너무 많은 인터럽트 요청이 들어오기 때문에 CPU 부하를 막아주며 CPU의 일을 부담하는 보조 일꾼입니다. 
또한, 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 방지합니다. 

### 메모리 
> 전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치입니다. 보통 RAM(Random Access Memory)를 메모리라고 합니다. 

CPU는 계산을 담당하고, 메모리는 기억을 담당합니다. 

### 타이머 
> 몇 초안에 작업이 끝나야 한다는 것을 정하고 특정 프로그램에 시간 제한을 거는 역할을 합니다. 

### 디바이스 컨트롤러
> 컴퓨터와 연결되어 있는 I/O 디바이스들의 작은 CPU를 말합니다. 

## 메모리 
>메모리 계층은 레지스터, 캐시, 메모리, 저장장치로 구성되어 있습니다. 

- 레지스터 : CPU안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적습니다. 
- 캐시 : L1, L2 캐시를 지칭합니다. 휘발성, 속도 빠름, 기억 용량이 적습니다.
- 주기억장치 : RAM을 가리킵니다. 휘발성, 속도 보통, 기억 용량이 보통입니다. 
- 보조기억장치 : HDD, SDD를 일컬으며 휘발성, 속도 낮음, 기억 용량이 많습니다. 


### 캐시 
> Cache는 데이터를 미리 복사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말합니다. 

이를 통해 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고 무언가를 다시 계산하는 시간을 절약할 수 있습니다. 

#### 지역성의 원리 
캐시 계층을 두는 것 말고 캐시를 직접 설정할때는 어떻게 해야 할까요??
이는 자주 사용하는 데이터를 기반으로 설정합니다. 자주 사용하는 데이터에 대한 근거는? 지역성입니다. 지역성은 `시간 지역성`과 `공간 지역성`으로 나뉩니다.

#### 시간 지역성
> 최근 사용한 데이터에 다시 접근하려는 특성을 말합니다.

#### 공간 지역성
> 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하려는 특성을 말합니다. 

### 캐시히트와 캐시미스
캐시히트 : 캐시에서 원하는 데이터를 찾은 경우
캐시미스 : 원하는 데이터가 캐시에 없어 주 메모리로 가서 데이터를 찾아오는 경우

캐시히트를 하게 되면 해당 데이터를 제어장치를 거쳐 가져오게 됩니다. 
위치도 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠릅니다.
반면에 캐시미스가 발생하면 메모리에서 가져오게 되는데, 이는 시스템 버스를 기반으로 작동하기 때문에 느립니다.

요약 : 
캐시히트 시 데이터를 `제어장치`에서 가져옴
캐시미스 시 데이터를 `메모리`에서 가져옴

### 캐시매핑
>캐시가 히트되기 위해 매빙하는 방법을 ㅁ라하며 CPU의 레지스터와 주 메모리간에 데이터를 주고받을 때를 기반으로 설정한다. 

레지스터는 주 메모리에 비하면 굉장히 작고 주 메모리는 굉장히 크기 때문에 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 이 매핑을 어떻게 하느냐가 중요합니다. 

매핑은 크게 3가지로 나뉩니다. 

1. 직접 매핑 : 메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20 이런 식으로 매핑하는 것을 말합니다. 처리가 빠르지만 충돌이 잦습니다. 

2. 연관 매핑 : 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑합니다. 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느립니다. 

3. 집합 연관 매핑 : 직접 매핑과 연관 매핑을 합쳐 놓은 매핑입니다. 순서는 일치시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색은 조금 더 효율적입니다. 예를 들어 메모리가 1~100이 있고 캐시가 1~10이 있다면 캐시 1~5에는 1~50의 데이터를 무작위로 저장시킵니다. 

### 웹 브라우저의 캐시
> 대표적인 캐시로는 웹 브라우저의 작은 저장소 쿠키, 로컬 스토리지, 세션 스토리지가 있습니다. 

이러한 것들은 보통 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 쓰입니다. 

### 쿠키 
**만료기한이 있는 키값 저장소입니다. **
same site 옵션을 strict로 섲어하지 않았을 경우 다른 도메인에서 요청했을 때 자동 전송되며, 4KB까지 데이터를 저장할 수 있고 만료기한을 정할 수 있습니다. 쿠키를 설정할 때는 document.cookie로 쿠키를 볼 수 없게 httponly 옵션을 거는 것이 중요하며, 클라이언트 또는 서버에서 만료기한 등을 저장할 수 있는데 보통 서버에서 만료기한을 정합니다.

### 로컬 스토리지 
**만료기한이 없는 키값 저장소입니다.**
10MB까지 저장할 수 있으며 웹 브라우저를 닫아도 유지되고 도메인 단위로 저장, 생성됩니다. HTML5를 지원하지 않는 웹 브라우저에는 사용할 수 없으며 클라이언트에서만 수정 가능합니다. 

### 세션 스토리지
**만료기한이 없는 키값 저장소입니다.**
탭 단위로 세션 스토리지를 생성하며, 탭을 닫을 때 해당 데이터가 삭제됩니다. 
5MB까지 저장이 가능하며 HTML5를 지원하지 않는 웹 브라우저에는 사용할 수 없으며 클라이언트에서만 수정 가능합니다. 

## 메모리 관리

### 가상 메모리 
>메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것을 말합니다. 

가상적으로 주어진 주소를 가상주소라고 하며, 실제 메모리상에 있는 주소를 실제 주소라고 합니다. 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 반환되며, 이 덕분에 사용자는 실제 주소를 의식할 필요 없이 프로그램을 구축할 수 있게 됩니다. 
가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어 있는 '페이지 테이블'로 관리됩니다. 이때 속도 향상을 위해 TLB를 사용합니다.

#### TLB
> 메모리와 CPU 사이에 있는 주소 반환을 위한 캐시입니다. 페이지 테이블에 있는 리스트를 보관하며 cpu가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층입니다. 

### swapping, 스와핑
만약 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생합니다. 이를 방지하기 위해 당장 사용하지 않는 영역을 하드디스크로 옮겨 필요할 때 RAM으로 불러와 올리고, 사용하지 않으면 그에 반대되는 동작을 합니다.

HDD <-> RAM

### Page fault, 페이지 폴트
프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 때 발생합니다. 
이때 운영체제는 아래와 같은 동작으로 페이지 폴트가 발생하지 않은 것처럼 보여줍니다. 
1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생시켜 운영체제에 알립니다.
2. 운영체제는 CPU의 동작을 잠시 멈춥니다.
3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾습니다. 물리 메모리에도 없다면 스와핑이 발동됩니다. 
4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화합니다.
5. 중단되었던 CPU를 다시 시작합니다. 

#### page, 페이지
> 가상 메모리를 사용하는 최소 크기 단위

#### frame, 프레임
>실제 메모리를 사용하는 최소 크기 단위 


### Thrashing, 스레싱
>메모리의 페이지 폴트율이 높은 것을 의미하며, 이는 컴퓨터의 심각한 성능 저하를 초래합니다.

메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생하는 것입니다. 
페이지 폴트가 일어나면 CPU 이용률이 낮아집니다. CPU 이용률이 낮아지게 되면 운영체제는 "CPU가 한가한가?" 라고 생각하여 가용성을 더 높이기 위해 더 많은 프로세스를 메모리에 올립니다. 
이와 같은 악순환이 반복되며 스레싱이 일어납니다.

이를 해결하기 위한 방법으로 메모리를 늘리거나 HDD -> SSD로 교체하는 방법이 있습니다. 
이외에 운영체제에서 작업 세트와 PFF를 이용하여 해결할 수 있습니다.

#### Working Set, 작업 세트
>프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것입니다. 미리 메모리에 로드하면 탐색에 드는 비용을 줄일 수 있고 스와핑을 줄일 수 있습니다.

#### PFF
> Page Fault Frequency는 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법입니다. 

만약 상한선에 도달한다면 페이지를 늘리고 하한선에 도달한다면 페이지를 줄입니다. 

### 메모리 할당
메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당으로 나뉩니다. 

#### 연속할당
연속적으로 공간을 할당하는 것을 말합니다. 
순차적으로 공간에 할당할 때, `고정 분할 방식`과, `가변 분할 방식`으로 할당하게 됩니다.

#### Fixed Partition Allocation, 고정 분할 방식
> 메모리를 미리 나누어 관리하는 방식이며, 메모리가 미리 나뉘어 있기 때문에 융통성이 없습니다. 내부 단편화가 발생합니다. 

#### Variable Partition Allocation, 가변 분할 방식
> 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용합니다. 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있습니다. 이는 최초적합, 최적적합, 최악적합이 있습니다. 

|이름|설명|
|:---|:---|
|최초적합|위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당합니다.|
|최적적합|프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당합니다.|
|최악적합|프로세스의 크기와 가장 많이 차이가 나는 홀에 할당합니다.|

※ Internal fragmentation, 내부 단편화 : 나눈 메모리의 크기보다 프로그램이 작아서 공간이 남는 현상
※ External fragmentation, 외부 단편화 : 나눈 메모리의 크기보다 프로그램이 더 큰 현상
※ Hole, 홀 : 할당할 수 있는 비어 있는 메모리 공간

### 불연속 할당
현재 운영체제가 사용하는 `페이징 기법` 중 하나.
메모리를 동일한 크기의 페이지로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당하는 것입니다.
페이징 기법 말고도 세그멘테이션, 페이지드 세그멘테이션이 있습니다.

#### Paging, 페이징
동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당합니다. 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해집니다.

#### Segmentation, 세그멘테이션 
페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식입니다.

프로세스는 코드, 데이터, 스택, 힙 등으로 이루어지는데, 코드와 데이터 등 이를 기반으로 나눌 수도 있고, 함수 단위로 나눌 수 있습니다. 공유와 보안 측면에서 좋으며 홀 크기가 균일하지 않은 문제가 발생합니다.

#### 페이지드 세그멘테이션
공유나 보안을 의미 단위의 세그먼트로 나누고, 물리적 메모리는 페이지로 나누는 것을 말합니다. 

#### 연속할당과 불연속할당의 차이
메모리의 낮은 주소 영역엔 커널이 상주해있고 메모리의 높은 주소 영역엔 사용자 프로그램이 올라가게 됩니다. 이때 사용자 프로그램을 ***할당하는 방식***에 따라 `연속 할당`과 `불연속 할당`으로 나눌 수 있습니다.

### 페이지 교체 알고리즘
메모리는 한정되어 있기 때문에 스와핑이 많이 일어납니다. 스와핑은 많이 일어나지 앟도록 설계되어야 하며 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어납니다.

#### Offline Algorithm, 오프라인 알고리즘
먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이며, 가장 좋은 방법입니다. 하지만 미래에 사용되는 페이지는 알 수 없으므로 사용할 수 없는 알고리즘이지만 다른 알고리즘과 성능 ㅂ교에 대한 기준을 제공합니다. 

#### FIFO
> first in first out은 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

#### LRU
Least Recentle Used는 참조가 가장 오래된 페이지를 바꾸는 방법입니다. 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야하는 문제점이 있습니다.

LRU 구현을 구현할 때는 보통 두 개의 자료 구조를 사용합니다. 
- 해시 테이블 : 이중 연결 리스트에서 빠르게 찾기 위해 사용합니다.
- 이중 연결리스트 : 한정된 메모리를 나타내기 위해 사용합니다.

#### NUR
> LRU에서 발전한 Not Used Recently 알고리즘입니다.

일명 Clock 알고리즘이라 하며 0과 1을 가진 비트를 둡니다.
시계 방향으로 돌면서 0을 방문하면 해당 프로세스를 교체하고 1로 바꾸는 알고리즘입니다.
0일 때는 미 방문 상태, 1일 때는 방문 상태를 의미합니다.

#### LFU
> Least Frequently Used는 가장 참조 횟수가 적은 페이지를 교체합니다.

즉, 많이 사용되지 않은 것을 교체하는 것입니다.

## 프로세스와 스레드
프로세스는 컴퓨터에서 실행되고 있는 프로그램을 말하며 CPU 스케줄링의 되는 작업이라는 용어와 거의 같은 의미로 쓰입니다.

### 프로세스와 컴파일 과정
프로세스는 프로그램으로부터 인스턴스화된 것을 말합니다. 
프로그램은 컴파일러가 컴파일 과정을 거쳐 컴퓨터가 이해할 수 있는 기계어로 번역되어 실행될 수 있는 파일이 되는 것을 의미하며 '컴파일 과정'이란 다음과 같습니다. 

#### 전처리
>소스 코드의 주석을 제거하고 #include 등 헤더 파일을 병합하여 매크로를 치환합니다.

#### 컴파일러
> 오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환합니다.

#### 어셈블러
>어셈블리어는 목적 코드(object code)로 변환됩니다. 이때 확장자는 운영체제마다 다른데 리눅스에서는 .o입니다. 

#### 링커
>프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일을 만듭니다. 실행 파일의 확장자는 .exe 또는 .out이라는 확장자를 갖습니다.

라이브러리는 크게 정적, 동적 라이브러리 두 개로 나뉩니다. 

#### 정적 라이브러리
프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식이며, 시스템 환경 등 외부 의존도가 낮고 코드 중복 등 메모리 효율성이 떨어지는 단점이 있습니다.

#### 동적 라이브러리 
프로그램 실행 시 필요할 때만 DLL이라는 함수 정보를 통해 참조하는 방식이며, 메모리 효율성에서의 장점과 외부 의존도가 높아진다는 단점이 있습니다. 

### 프로세스의 상태
#### Create, 생성 상태
프로세스가 생성된 상태를 의미하며 fork, exec 함수를 통해 생성합니다. 이때 PCB가 할당됩니다.

#### fork()
부모 프로세스의 주소 공간을 그대로 복사하며, 새로운 자식 프로세스를 생성하는 함수입니다. 
주소 공간만 복사할 뿐이지 부모 프로세스의 비동기 작업 등을 상속하지 않습니다. 

#### exec()
새로운 프로세스를 생성하는 함수입니다.

#### Ready, 대기 상태
메모리 공간이 충분하면 메모리를 할당받고 아니면 아닌 상태로 대기하고 있으며 CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태입니다.

#### Ready Suspended, 대기 중단 상태
메모리 부족으로 일시 중단된 상태입니다. 

#### Running, 실행 상태
CPU 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태를 의미합니다. 
이를 CPU burst가 일어났다고도 표현합니다.

#### Blocked, 중단 상태
어떤 이벤트가 발생한 이후 기다리며 프로세스가 차단된 상태입니다. IO디바이스에 의한 인터럽트로 이런 현상이 많이 발생합니다. 

#### Blocked Suspended, 일시 중단 상태
대기 중단과 유사합니다. 중단된 상태에서 프로세스가 실행되려고 했지만 메모리 부족으로 일시 중단된 상태입니다. 

#### Terminated, 종료 상태 
메모리와 CPU 소유권을 모두 놓고 가는 상태를 말합니다. 

### 프로세스의 메모리 구조
동적 영역, 정적 영역으로 나눌 수 있습니다.

![](https://velog.velcdn.com/images/oyunseong/post/a3883821-4eee-4995-a227-574dd42776d6/image.png)

#### 스택
지역변수, 매개변수, 함수가 저장되고 ***컴파일 시에 크기가 결정되며*** `동적`인 특징을 갖습니다.

#### 힙
동적 할당할 때 사용되며 ***런타임 시 크기가 결정됩니다.*** 예를 들어 벡터 같은 동적 배열은 당연히 힙에 동적 할당됩니다. 힙은 `동적`인 특징을 갖습니다.

#### 데이터 영역
전역변수, 정적변수가 저장되고, 정적인 특징을 갖는 프로그램이 종료되면 사라지는 변수가 들어 있는 영역입니다. 

데이터 영역은 BSS, Data 영역으로 나뉩니다.
BSS segment : 초기화가 되지 않은 변수가 0으로 초기화되어 저장됩니다. 
Data segment : 0이 아닌 다른 값으로 할당된 변수들이 저장됩니다. 

#### 코드 영역
프로그램에 내장되어 있는 소스 코드가 들어가는 영역입니다. 이 영역은 수정 불가능한 기계어로 저장되어 있으며 정적인 특징을 갖습니다. 

### PCB, 프로세스 제어 블록
Process Control Block은 운영체제에서 프로세스에 대한 메타데이터를 저장한 `데이터`를 말합니다.
프로세스가 실행되면 프로세스가 생성되고 프로세스 주소 값들에 앞서 설명한 스택, 힙 등의 구조를 기반으로 메모리가 할당됩니다. 그리고 이 프로세스의 메타데이터들이 PCB에 저장되어 관리됩니다. 이는 프로세스의 중요한 정보를 포함하고 있기 때문에 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리됩니다. 

※메타데이터 : 데이터에 관한 구조화된 데이터이자 데이터를 설명하는 작은 데이터

### PCB의 구조 
- 프로세스 스케줄링 상태 
- 프로세스 ID
- 프로세스 권한
- 프로세스 카운터
- CPU 레지스터
- CPU 스케줄링 정보
- 계정 정보
- I/O 상태 정보

#### Context switching, 컨텍스트 스위칭
PCB를 교환하는 과정입니다. 
한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생합니다. 컴퓨터는 많은 프로그램을 동시에 돌리는 것처럼 보이지만 어떠한 시점에서 실행되고 있는 프로세스는 단 한개입니다. 컨텍스트 스위칭이 아주 빠른 속도로 실행되고 있기 때문에 동시에 실행되는 것처럼 보이는 것입니다. 
이 설명은 싱클코어 기준의 설명입니다. 

![](https://velog.velcdn.com/images/oyunseong/post/8ca1cade-01f5-4694-82b9-ceee1e09dd0b/image.png)

사진 출처 : http://blog.skby.net/%EB%AC%B8%EB%A7%A5%EA%B5%90%ED%99%98-context-switching/

1. 한 개의 프로세스 A가 실행하다 멈추고 A의 PCB를 저장
2. 프로세스 B를 로드하여 실행 
3. B의 PCB를 저장하고 A의 PCB로드

스위칭을 하면 위 그림에 idle time(유효시간)이 발생하는 것을 볼 수 있습니다.

#### 캐시미스
컨텍스트 스위칭이 일어날 때 프로세스가 가지고 있는 메모리 주소가 그대로 있으면 잘못된 주소 변환이 생기므로 캐시클리어 과정을 겪게 되고 이 때문에 캐시미스가 발생합니다. 

#### 스레드에서의 컨텍스트 스위칭
컨텍스트 스위칭은 스레드에서도 일어납니다. 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 스레드 컨텍스트 스위칭의 경우 비용이 더 적도 시간도 더 적게 걸립니다. 

### 멀티프로세싱
여러 개의 `프로세스`, 즉 멀티프로세스를 통해 동시에 두 가지 이상의 일을 수행할 수 있는 것을 말합니다. 이를 통해 하나 이상의 일을 병렬로 처리할 수 있으며 특정 프로세스의 메모리, 프로세스 중 일부에 문제가 발생되더라도 다른 프로세스를 이용해서 처리할 수 있으므로 신뢰성이 높은 강점이 있습니다. 

#### 웹 브라우저 
웹 브라우저는 멀티프로세스 구조를 가지고 있으며 아래와 같습니다.
- 브라우저 프로세스
- 렌더러 프로세스
- 플러그인 프로세스
- GPU 프로세스 

#### IPC
멀티프로세스는 Inter Process Communication가 가능하며 IPC는 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘을 뜻합니다. 
클라이언트와 서버를 예로 들 수 있는데, 클라이언트는 데이터를 요청하고 서버는 클라이언트 요청에 응답하는 것도 IPC의 예입니다. IPC의 종류는 아래에 설명하겠습니다!

#### 공유 메모리 
여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 `공유버퍼`를 생성하는 것을 말합니다. 

기본적으로 각 프로세서의 메모리를 다른 프로세스가 접근할 수 없지만 공유 메모리를 통해 여러 프로세스가 하나의 메모리를 공유할 수 있습니다. 
이 방식을 사용하면 메모리 자체를 공유하기 때문에 불필요한 데이터 복사의 오버헤드가 발생하지 않아 가장 빠르며 같은 메모리 영역을 여러 프로세스가 공유하기 때문에 동기화가 필요합니다. 

#### 파일
디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터를 말합니다. 이를 기반으로 프로세스 간 통신을 합니다. 

#### 소켓
동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터를 의미하며 TCP와 UDP가 있습니다. 

#### Unamed pipe, 익명파이프
프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고받으며, 단방향 방식의 읽기 전용, 쓰기 전용 파이프를 만들어서 작동하는 방식을 말합니다. 
이는 부모, 자식 프로세스 간에만 사용할 수 있으며 다른 네트워크상에서는 사용이 불가합니다. 

그 이유로는 이름이 없기 때문에 외부 프로세스에서는 이 파이프를 부를 수 없는데 부모가 자식 프로세스를 생성하는 경우 파일 지정 번호를 상속받아 익명 파이프로 통신할 수 있습니다. 

#### Named pipe, 명명된 파이프, 지명 파이프
파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 이중 파이프를 말합니다. 

통신을 위한 별도의 파이프를 제공하며, 여러 파이프를 동시에 사용할 수 있습니다. 프로세스끼리 또는 다른 네트워크상의 컴퓨터와도 통신할 수 있습니다. 

즉, 전혀 모르는 상태의 프로세스들과 통신합니다.

#### 메시지 큐
데이터 구조 형태로 관리하는 것을 의미합니다. 이는 커널의 전역변수 형태 등 커널에서 전역적으로 관리되며 다른 IPC방식에 비해서 사용 방법이 매우 직관적이고 간단하며 다른 코드의 수정 없이 단지 몇 줄의 코드를 추가시켜 간단하게 메시지 큐에 접근할 수 있는 장점이 있습니다.

### 스레드와 멀티스레딩

#### 스레드
>프로세스의 실행 가능한 가장 작은 단위입니다.

프로세스는 여러 스레드를 가질 수 있습니다. 
코드, 데이터, 스택, 힙을 각각 생성하는 프로세스와는 달리 스레드는 코드, 데이터, 힙은 스레드끼리 서로 공유합니다. 그 외의 영역은 각각 생성됩니다. 


#### 멀티스레딩
프로세스 내 작업을 여러 개의 스레드, 멀티스레드로 처리하는 기법이며 스레드끼리 서로 자원을 공유하기 때문에 효율성이 높습니다. 
동시성에도 큰 장점이 있습니다. 하지만 한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐 스레드로 이루어져 있는 프로세스에 영향을 줄 수 있는 단점이 있습니다. 

※ 동시성 : 서로 독립적인 작업들을 작은 단위로 나누고 동시에 실행되는 것처럼 보여주는 것 

멀티 스레드의 종류에는 메인 스레드, 컴포지터 스레드, 워커 스레드, 레스터 스레드 등이 있습니다. 

### 공유 자원과 임계 영역

#### Shared resource, 공유 자원
시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수 등을 의미합니다. 이 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황을 경쟁 상태(race condition)라고 합니다. 동시에 접근을 시도할 때 접근의 타이밍이나 순서 등이 결괏값에 영향을 줄 수있는 상태를 뜻합니다.

프로세스 A와 B가 동시에 접근하여 타이밍이 서로 꼬여 정상 결괏값과 다른 결과값이 출력되는 것입니다. 

#### Critical section, 임계 영역
공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 영역을 임계 영역이라고 합니다. 
임계 영역을 해결하기 위한 방법은 크게 뮤텍스, 세마포어, 모니터 세 가지가 있으며, 이 방법 모두 상호 배제, 한정 대기, 융통성이란 조건을 만족합니다. 
이 방법에 토대가 되는 메커니즘은 잠금(lock)입니다. 

※ 상호 배제 : 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없다.
※ 한정 대기 : 특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안 된다. 
※ 융통성 : 한 프로세스가 다른 프로세스의 일을 방해해서는 안 된다. 

#### Mutex, 뮤텍스
공유 자원을 사용하기 전에 설정하고 사용한 후에 해제하는 잠금입니다. 잠금이 설정되면 다른 스레드는 잠긴 코드 영역에 접근할 수 없습니다. 또한 뮤텍스는 하나의 상태만 가집니다.
여기서 상태는 잠금 또는 잠금 해제 입니다. 

#### Semaphore, 세마포어 
일반화된 뮤텍스입니다. 간단한 정수 값과 두 가지 함수 wait(P함수), signal(V함수)로 공유 자원에 대한 접근을 처리합니다.
wait() : 자신의 차례가 올 때까지 기다리는 함수
signal() : 다음 프로세스로 순서를 넘겨주는 함수

1. 프로세스가 공유자원에 접근
2. 프로세스는 세마포어 값을 수정 wait()
3. 다 쓰면 signal()

프로세스들은 동시에 세마포어 값을 수정할 수 없습니다.

#### 바이너리 세마포어
0과 1 두 가지 값만 가질 수 있는 세마포어입니다. 
뮤텍스와 거의 유사하지만 엄밀히 말하면 뮤텍스는 리소스에 대한 접근을 동기화하는 데 사용되는 잠금 메커니즘이고, 세마포어는 신호를 기반으로 상호 배제가 일어나는 신호 메커니즘 입니다. 

#### 카운팅 세마포어
여러 개의 값을 가질 수 있는 세마포어

#### 모니터 
둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 제공합니다. 

모니터는 모니터큐를 통해 공유 자원에 대한 작업들을 순차적으로 처리합니다. 
세마포어보다 구현하기 쉬우며 모니터에서 상호 배제는 자동인 반면에, 세마포어는 명시적으로 구현해야 합니다. 

### Deadlock, 교착 상태
두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태를 말합니다. 

![업로드중..](blob:https://velog.io/1b7eaa72-7f74-4bbc-8855-b94008290a44)

사진 출처 :  https://coding-factory.tistory.com/311

프로세스 A와 B의 어떤 자원을 요청할 때 프로세스 B도 A가 점유하고 있는 자원을 요청하는 것입니다. 

#### 교착 상태의 원인
- 상호 배제
- 점유 대기
- 비선점
- 환형 대기

#### 교착 상태의 해결 방법
1. 애초에 잘 설계한다.
2. 교착 상태 가능성이 없을 때만 자원 할당되며, 프로세스당 요청할 자원들의 최대치를 통해 자원 할당 가능 여부를 파악하는 `은행원 알고리즘`을 사용합니다.
3. 발생 시 사이클이 있는지 찾아보고 이에 관한 프로세스를 한 개씩 지웁니다. 
4. 매우 드물게 일어나는 현상으로 발생 시 사용자가 직접 작업을 종료합니다. 

※ 은행원 알고리즘 : 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고 안정 상태로 가도록 자원을 할당하는 알고리즘

### CPU 스케줄링 알고리즘
CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당합니다. 
이 알고리즘은 CPU는 많이 사용하지만 자원은 적게 응답시간은 짧게 설정하는 것을 목표로 합니다. 

### non-preemptive, 비선점형 방식
프로세스가 **스스로 CPU 소유권을 포기**하는 방식이며, 강제로 프로세스를 중지하지 않습니다. 따라서 컨텍스트 스위칭으로 인한 부하가 적습니다. 

#### FCFS
First Come, First Served는 가장 먼저 올라온 것을 가장 먼저 처리하는 알고리즘입니다. 
길게 수행되는 프로세스 때문에 '**준비 큐에서 오래 기다리는 현상**'이 발생하는 단점이 있습니다.

#### SJF
Shortest Job First는 실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘입니다. 
긴 시간을 가진 프로세스가 실행되지 않는 현상(starvation)이 일어나며 평균 대기 시간이 가장 짧습니다. 하지만 실제로는 실행 시간을 알 수 없기 때문에 과거의 실행했던 시간을 토대로 추측해서 사용합니다. 

#### 우선순위
기존 SJF 스케줄링의 경우 긴 시간을 가진 프로세스가 실행되지 않는 현상이 있습니다.
이는 **오래된 작업일수록 우선순위를 높이는 방법(aging)**을 통해 단점을 보완한 알고리즘입니다.

### Preempive, 선점형 방식
선점형 방식는 현대 운영체제가 쓰는 방식으로 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단시켜 버리고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방식을 말합니다.

#### RR, 라운드 로빈
현대 컴퓨터가 쓰는 스케줄링인 우선선위 스케줄링의 일종으로 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘입니다. 

일반적으로 전체 작업 시간은 길어지지만 평균 응답 시간은 짧아진다는 특징이 있습니다.

이 알고리즘은 로드 밸런서에서 트래픽 분산 알고리즘으로도 쓰입니다. 

#### SRF
중간에 실행 시간이 더 짧은 작업이 들어오면 중지하고 해당 프로세스를 수행하는 알고리즘입니다.

#### 다단계 큐
우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 라운드 로빈이나 FCFS등 다른 스케줄링 알고리즘을 적용한 것을 말합니다. 큐 간의 프로세스 이동이 안 되므로 스케줄링 부담이 적지만 유연성이 떨어지는 특징이 있습니다.






